---
title: "Lab2_Esther"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(ggplot2)
library(dplyr)
library(GGally)
```

```{r read}
#read in dataset
drive <- read.csv("./data/bad-drivers.csv") 
head(drive)
#rename the cols 
drive <- drive %>% rename(amt_per_bil_miles = Number.of.drivers.involved.in.fatal.collisions.per.billion.miles, 
                          pct_speeding = Percentage.Of.Drivers.Involved.In.Fatal.Collisions.Who.Were.Speeding, 
                          pct_alcohol_impaired = Percentage.Of.Drivers.Involved.In.Fatal.Collisions.Who.Were.Alcohol.Impaired, 
                          pct_not_distracted = Percentage.Of.Drivers.Involved.In.Fatal.Collisions.Who.Were.Not.Distracted, 
                          pct_no_previous = Percentage.Of.Drivers.Involved.In.Fatal.Collisions.Who.Had.Not.Been.Involved.In.Any.Previous.Accidents, 
                          premiums = Car.Insurance.Premiums...., 
                          losses = Losses.incurred.by.insurance.companies.for.collisions.per.insured.driver....)
colnames(drive)
```

```{r eda}
#draftsmans plot
pairs(drive, gap = 0)
#histogram
ggplot(drive, aes(x = pct_speeding)) +
  geom_histogram(bins = 15)
```
Premiums and losses have a positive relationship. State, accidents per billion miles, and percent speeding seem not to have relationships with premiums. 

I don't think that the distribution of the independent variable will cause any problems for doing a regression because it is not horribly distributed. I think that it is close enough to normal.
```{r regression}
#Simple
reg01 <- lm(premiums ~ losses, drive)
summary(reg01)
#Multiple
reg02 <- lm(premiums ~ amt_per_bil_miles + losses, drive)
summary(reg02)
#Polynomial
reg03 <- lm(premiums ~ poly(losses, 2, raw=TRUE), drive)
summary(reg03)
#plot
ggplot(drive, aes(x = amt_per_bil_miles, y = premiums)) +
  geom_point()

ggplot(drive, aes(x = losses, y = premiums)) +
  geom_point() +
  stat_smooth(method='lm', formula = y~x)
```
I chose the simple linear regression because it has a small p value. and Also it kind of looks like our data but secretly the data has a curve.The coefficients for the SLR are the intercept 285, and the slope 4.47. That means that the predicted premium at 0 losses is 285, and that for every unit increase of losses, premium increases by 4.47. Both the intercept and the slope have a very small p value which indicates that there is a relationship between losses and premiums. I think that it may be fair to use losses to predict premiums because insurance companies will want to charge more if there are more serious accidents which cost them more money. But also it does not really make that much sense I guess.

The multiple linear regression includes another predictor variable amt_per_bil_miles, which means that we think that amt_per_billion_miles is something else that influences premiums. It has another slope for the predictor variable so actually it has another dimension. It turns out that it has a negative relationship with premiums and its slope is -7.6774 which means for every unit increase in people involved in accidents per billion miles, premiums go down by 7.6774. The slope of losses is still 4.4, and the p value is even tinier. 

```{r holdout}
rows <- sample(1:51, 10)

test <- drive[rows,]
train <- drive[-rows,]

#Simple
reg01 <- lm(premiums ~ losses, train)
summary(reg01)
#Multiple
reg02 <- lm(premiums ~ amt_per_bil_miles + losses, train)
summary(reg02)
#Polynomial
reg03 <- lm(premiums ~ poly(losses, 2, raw=TRUE), train)
summary(reg03)

N <- nrow(test)
mse_01 <- sum((predict(reg01, test))^2)/N ; mse_01
mse_02 <- sum((predict(reg02, test))^2)/N ; mse_02
mse_03 <- sum((predict(reg03, test))^2)/N ; mse_03
```
I would not choose any of them because they are all bad but the SLR has the lowest MSE but not by much so it doesn't really matter in my opinion because the difference is not significant.


```{r cross val}
# number of folds
k <- 5

piece <- split(drive[sample(nrow(drive)),], 1:5)

crossValResults <- data.frame(matrix(ncol = 3, nrow = 5))
x <- c("simple", "multiple", "poly")
colnames(crossValResults) <- x


#simple linear regression
  crossValResults$simple = sapply(piece, 
       function(TestData){
          testIndexes <- as.numeric(row.names(TestData))
          
          testData <- drive[testIndexes, ]
          trainData <- drive[-testIndexes, ]
          
          newlm <- lm(trainData$premiums ~ trainData$losses, data = trainData)
  
          MSE = function(model,data){
          N = nrow(testData)
          return(sum((predict(model, data) - data$premiums)^2)/N)
          }
          return(MSE(newlm, testData))
       })
       
#multiple linear regression
  crossValResults$multiple = sapply(piece, 
       function(TestData){
          testIndexes <- as.numeric(row.names(TestData))
          
          testData <- drive[testIndexes, ]
          trainData <- drive[-testIndexes, ]
          
          newlm <- lm(trainData$premiums ~ trainData$losses + trainData$amt_per_bil_miles, data = trainData)
  
          MSE = function(model,data){
          N = nrow(testData)
          return(sum((predict(model, data) - data$premiums)^2)/N)
          }
          return(MSE(newlm, testData))
       })
  
#polynomial regression
  crossValResults$poly = sapply(piece, 
       function(TestData){
          testIndexes <- as.numeric(row.names(TestData))
          
          testData <- drive[testIndexes, ]
          trainData <- drive[-testIndexes, ]
          
          newlm <- lm(trainData$premiums ~ poly(trainData$losses, 2, raw = TRUE), data = trainData)
  
          MSE = function(model,data){
          N = nrow(testData)
          return(sum((predict(model, data) - data$premiums)^2)/N)
          }
          return(MSE(newlm, testData))
       })
  
cvErrorsimple = mean(crossValResults$simple) ; cvErrorsimple
cvErrormultiple = mean(crossValResults$multiple) ; cvErrormultiple
cvErrorpoly = mean(crossValResults$poly) ; cvErrorpoly

#copy pasting isnt good but idk how else to do this.. !!!!?
```
The cV compared to the holdout is lower than the MSEs I calculated for holdout and I don't know why, I probably did something very wrong.On average the simple linear regression is lower than the multiple linear regression but not by much.

The dataset is information about each state about driving statistics, including how many accidents occur, amount that were speeding, alcohol impaired, and distracted when accidents occurred. It also has the premiums in each state which I assume is the average price of premium. We don't know when this data is collected.

I will use simple linear, multiple linear, and polynomial regression to make predictions.

In order to pick the best model, you can compare their test MSE which shows how close their predictions are when exposed to new data. MSE is calculated by squaring the residuals and taking the mean of this value. MSE changes with the amount of bias and variance in our model , and it can also be represented by variance + bias^2 + error. We can adjust the variance and bias in our model by adjusting how many parameters are in the model.

